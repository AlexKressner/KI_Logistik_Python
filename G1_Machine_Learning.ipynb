{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexKressner/KI_Logistik_Python/blob/main/G1_Machine_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64b0765e-bc90-46b8-8c66-0123b137bf19",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": [],
        "id": "64b0765e-bc90-46b8-8c66-0123b137bf19"
      },
      "source": [
        "# Übersicht\n",
        "1. [Problem/ Business Understanding](#problem)\n",
        "1. [Data Understanding & Data Exploration](#data)\n",
        "  1. [Erster Überblick](#overview)\n",
        "  1. [Target](#target)\n",
        "  1. [Features](#feature)\n",
        "1. [Machine Learning für Regressionsprobleme](#regression)\n",
        "1. [Machine Learning für Klassifikationsprobleme](#klassifikation)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4568c8d2-8df2-406b-9dd1-a3420d979671",
      "metadata": {
        "id": "4568c8d2-8df2-406b-9dd1-a3420d979671"
      },
      "source": [
        "# Übungsaufgaben\n",
        "- [Data Exploration - Track & Trace](#tt_eda)\n",
        "- [Machine Learning - Track & Trace](#tt_ml)\n",
        "- [Abschlussübung ML](#final)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 Problem/ Business Understanding <a class=\"anchor\" id=\"problem\"></a>\n",
        "Sie kennen bereits die Daten zu den Fussballweltmeisterschaften von 1930 bis 2014. In diesen ist jedes einzelne Weltmeisterschaftsspiel dokumentiert - von der Zuschauerzahl bis zum Endergebnis. \n",
        "\n",
        "Wir werden nun versuchen, die Anzahl der in einem Spiel geschossenen Tore nach Abschluss der ersten Halbzeit vorherzusagen. Durch die Nutzung von maschinellen Lernverfahren versuchen wir aus den zur Halbzeit vorliegenden Daten Muster zu erkennen, die eine zuverlässige Vorhersage der geschossenen Tore erlaubt. \n",
        "\n",
        "Zunächst überlegen wir uns, welche Daten (Features) einen Einfluss auf die Anzahl der geschossenen Tore haben. Mit Sicherheit ist in diesem Zusammenhang die Anzahl der zur Halbzeit geschossenen Tore eine wichtige Information. Zusätzlich kann man sich aber auch die folgenden Fragen stellen:\n",
        "- Hat die Spielpaarung einen Einfluss auf die Anzahl der Tore?\n",
        "- Hat die Anzahl der Zuschauer einen Einfluss auf die Anzahl der geschossenen Tore?\n",
        "- Fallen mehr Tore in einem Vorrundenspiel im Vergleich zu einem Halbfinale?\n",
        "- ...\n",
        "\n",
        "Sicherlich finden wir auf jede einzelne Frage auch ohne maschinelle Lernverfahren durch eine tiefergehende Datenanalse erste Antworten. Die Bewertung der Einflüsse in ihrer Kombination ist aber schon äußerst schwierig.\n",
        "\n",
        "Maschinelle Lernverfahren helfen hier enorm. Wir müssen lediglich die Daten in geeigneter Weise aufbereiten, einen passenden Algorithmus auf diese anwenden und erhalten anschließend Prognosen zur interessierten Zielgröße oder Aussagen über die Bedeutung einzelner Features."
      ],
      "metadata": {
        "id": "MoVOHMi014E3"
      },
      "id": "MoVOHMi014E3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Frage:** Welchem Teilgebiet des maschinellen Lernens ist die oben beschriebene Problemstellung zuzuordnen? Supervised oder Unsupervised Learning?"
      ],
      "metadata": {
        "id": "bKCLGPXZXjl2"
      },
      "id": "bKCLGPXZXjl2"
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mYYdkl0dZSD5"
      },
      "id": "mYYdkl0dZSD5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Frage:** Handelt es sich um ein Regressions- oder Klassifikationsproblem?"
      ],
      "metadata": {
        "id": "jfqfGQAZZTbG"
      },
      "id": "jfqfGQAZZTbG"
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "L3PLvd_iZdQq"
      },
      "id": "L3PLvd_iZdQq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 Data Understanding & Exploration <a class=\"anchor\" id=\"data\"></a>\n",
        "In einem ersten Schritt ist es wichtig, dass Sie sich einen Überblick zu den vorhandenen Daten verschaffen, d.h.:\n",
        "- Wie groß ist der Datensatz (Zeilen/Spalten)\n",
        "- Was bedeuten die einzelnen Werte in den Spalten (Features)?\n",
        "- Wie sind die Werte der einzelnen Features verteilt?\n",
        "- Gibt es fehlende Werte, die Sie bereinigen müssen?\n",
        "- Wie sin die Zusammenhänge zwischen den Features?\n",
        "- ...\n",
        "\n",
        "Besonders hilfreich sind an dieser Stelle Visualisierung, die Ihnen einen Überblick zu den Daten geben und bereits etwaige Zusammenhänge zwischen Features und/oder Target aufzeigen!"
      ],
      "metadata": {
        "id": "mstNne1_1OrN"
      },
      "id": "mstNne1_1OrN"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd # zur Datenanalyse\n",
        "import matplotlib.pyplot as plt # zur Datenvisualisierug\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "sUGf06iS1arF"
      },
      "id": "sUGf06iS1arF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Google-Drive einbinden\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "I-5QslQG1kr3"
      },
      "id": "I-5QslQG1kr3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Daten laden\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/WorldCupMatches.txt\")\n",
        "\n",
        "# Die folgende Datenaufbereitung ist für Sie nicht relevant!\n",
        "data = data.astype({\"Datetime\": \"M\", \"RoundID\": \"O\", \"MatchID\": \"O\"}, errors='raise') \n",
        "data.dropna(inplace=True)\n",
        "data.replace(' ', np.nan, inplace=True)\n",
        "data[\"Hour\"] = data[\"Datetime\"].dt.hour\n",
        "data[\"Weekday\"] = data[\"Datetime\"].dt.day_name()\n",
        "data.Stage.replace(r'Group(.*)', 'Group', regex=True, inplace=True)\n",
        "data.Stage.replace('First round', 'Group', inplace=True)\n",
        "data.Stage.replace('Preliminary round', 'Group', inplace=True)\n",
        "data.Stage.replace(r'.+third.+', 'Third place', regex=True, inplace=True)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "9GLKqz311sMC"
      },
      "id": "9GLKqz311sMC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Target <a class=\"anchor\" id=\"target\"></a>\n",
        "Bei dem Target handelt es sich um die Zielgröße, welche wir prognostizieren wollen. In diesem Fall die Anzahl der geschossenen Tore in der regulären Spielzeit plus etwaiger Verlängerung!"
      ],
      "metadata": {
        "id": "gHe7yez1cvd0"
      },
      "id": "gHe7yez1cvd0"
    },
    {
      "cell_type": "code",
      "source": [
        "# Berechnung neue Spalte\n",
        "data[\"Total Goals\"] = data[\"Home Team Goals\"] + data[\"Away Team Goals\"]"
      ],
      "metadata": {
        "id": "dsgH-wDDcy3P"
      },
      "id": "dsgH-wDDcy3P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"Total Goals\"].plot(\n",
        "    kind=\"hist\", \n",
        "    title= \"Histogramm Total Goals\",\n",
        "    figsize=(8,4),\n",
        "    color=\"c\",\n",
        "    edgecolor='k',\n",
        "    density=True,\n",
        "    alpha=0.8\n",
        "    )\n",
        "plt.plot()"
      ],
      "metadata": {
        "id": "dDX0eDzSEJE1"
      },
      "id": "dDX0eDzSEJE1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Frage:** Warum ist es unabdingbar die folgenden Spalten zu löschen?"
      ],
      "metadata": {
        "id": "n8spg3_3V4jg"
      },
      "id": "n8spg3_3V4jg"
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop(columns=[\"Home Team Goals\", \"Away Team Goals\"], inplace=True)"
      ],
      "metadata": {
        "id": "_A1fb49Dzfj7"
      },
      "id": "_A1fb49Dzfj7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Features <a class=\"feature\" id=\"overview\"></a>\n",
        "Bei den Features handelt es sich um die Variablen, die zur Vorhersage des Targets verwendet werden - in diesem Fall die Anzahl der geschossenen Tore. \n",
        "\n",
        "Zum einen müssen Sie zunächst überlegen, welche der ursprünglichen Features einen Beitrag zur Erklärung des Target leisten können und ob diese noch anzupassen sind. \n",
        "\n",
        "Zum anderen leitet man regelmäßig aus den ursprünglichen Features weitere Features ab - in der Annahme, dass diese einen Beitrag zur Vorhersage des Target leisten."
      ],
      "metadata": {
        "id": "615_jEIAckP6"
      },
      "id": "615_jEIAckP6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Relevante Features**"
      ],
      "metadata": {
        "id": "_QJIYMHSYNO-"
      },
      "id": "_QJIYMHSYNO-"
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "BpzwpJM_0iUK"
      },
      "id": "BpzwpJM_0iUK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "id": "t5AFWLcF1f1X"
      },
      "id": "t5AFWLcF1f1X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "irrelevant = [\"Year\", \"City\", \"Win conditions\", 'Referee', 'Stadium',\n",
        "              'Assistant 1', 'Assistant 2', 'RoundID', 'MatchID',\n",
        "              \"Home Team Initials\", \"Away Team Initials\", \"Datetime\"\n",
        "              ]"
      ],
      "metadata": {
        "id": "N-Soo-VLjben"
      },
      "id": "N-Soo-VLjben",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Durch inplace=True müssen Sie nicht schreiben: data = data.drop(...)\n",
        "data.drop(columns=irrelevant, inplace=True)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "tuJugYtYkFxu"
      },
      "id": "tuJugYtYkFxu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Features zu den zur Halbzeit geschossenen Toren**"
      ],
      "metadata": {
        "id": "azZiBAnmYWQ7"
      },
      "id": "azZiBAnmYWQ7"
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"Half-time Goals\"] = data[\"Half-time Home Goals\"] + data[\"Half-time Away Goals\"]\n",
        "data[\"Half-time Goals Difference\"] = abs(data[\"Half-time Home Goals\"] - data[\"Half-time Away Goals\"])"
      ],
      "metadata": {
        "id": "2EcKxGXSa6kB"
      },
      "id": "2EcKxGXSa6kB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"Half-time Goals Difference\"].unique()"
      ],
      "metadata": {
        "id": "m0rHvOSWgNn-"
      },
      "id": "m0rHvOSWgNn-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"Half-time Goals Difference\"].value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "POwMS5lJWpdI"
      },
      "id": "POwMS5lJWpdI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nach den vorausgegangenen Datenmanipulationen erhalten wir nun den folgenden Dataframe (Target + Features), mit dem wir bei der Anwendung maschineller Lernverfahren weiterarbeiten werden."
      ],
      "metadata": {
        "id": "MLTSw41JkZQP"
      },
      "id": "MLTSw41JkZQP"
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "A0mRlGDvliHt"
      },
      "id": "A0mRlGDvliHt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 Korrelationen <a class=\"feature\" id=\"corr\"></a>\n",
        "Sie erhalten einen ersten sehr guten Eindruck von Zusammenhängen zwischen Features und/ oder Target, wenn Sie Korrelationskoeffizienten berechnen. Mithilfe von `pandas` gelingt dies mühelos.\n"
      ],
      "metadata": {
        "id": "HreQTaeJaI34"
      },
      "id": "HreQTaeJaI34"
    },
    {
      "cell_type": "code",
      "source": [
        "correlation_matrix = data.corr()"
      ],
      "metadata": {
        "id": "Mq2rVXYgl0tq"
      },
      "id": "Mq2rVXYgl0tq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Korrelationskoeffizient**\n",
        "\n",
        "Mit der `pandas`-Funktion `.corr()` berechnen Sie den [Korrelationskoeffizienten nach Pearson](https://de.wikipedia.org/wiki/Korrelationskoeffizient). Dieser misst den \"linearen\" Zusammenhang zwischen zwei stetigen Merkmalen. Der Koeffizient reicht von 1 bis -1. Für den Fall, dass er nahe 1 liegt, bedeutet dies, dass eine starke positive Korrelation besteht, d.h. \"wenn Werte des Merkmals `x` steigen, steigen auch solche des Merkmals `y`\"! Der umgekehrte Fall gilt für Koeffizienten, die nahe -1 liegen. Bitte behalten Sie in Erinnerung, dass der Korrelationskoeffizient nach Pearson nur lineare Zusammenhänge erfasst. Regelmäßig finden Sie aber auch nicht-lineare Korrelationen, die dann nicht erfasst werden ([Beispiel](https://de.wikipedia.org/wiki/Korrelationskoeffizient#/media/Datei:Correlation_examples.png))."
      ],
      "metadata": {
        "id": "z7_h_k2ba1Hz"
      },
      "id": "z7_h_k2ba1Hz"
    },
    {
      "cell_type": "code",
      "source": [
        "correlation_matrix[\"Total Goals\"].sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "pjRo2lnnazcD"
      },
      "id": "pjRo2lnnazcD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Übung Datenexploration mit Track & Trace Daten <a class=\"anchor\" id=\"tt_eda\"></a>\n",
        "**Einführung**\n",
        "\n",
        "Ein Automobilhersteller hat weltweit verteilte Produktionsstandorte, u.a. auch ein Werk in den USA. Dieses Werk wird mit diversen Bauteilen zur Herstellung von Fahrzeugen aus Europa beliefert. \n",
        "\n",
        "Zur Erhöhung der Transparenz in der Supply Chain wurde vor kurzer Zeit Track und Trace System aufgebaut, welches Daten für einzelne Sendungen an definierten Standorten in der Lieferkette aufnimmt. Die Daten finden Sie nachfolgend:"
      ],
      "metadata": {
        "id": "GcDczFUf0bWf"
      },
      "id": "GcDczFUf0bWf"
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/KI_LOG_mit_PYTHON/track_trace.txt\")\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "RK6PYPMK0TfF"
      },
      "id": "RK6PYPMK0TfF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Jeder einzelne Container (`ContainerNumber`) ist einer Sendung zugeordnet, wobei jede Sendung eine eindeutige Kennzeichnung (`Shipment Number`) aufweist. Zu jeder Sendung werden definierte Events aufgenommen. Diese beinhalten den Namen des Events (`EventName`), die Zeit des Events (`EventTim`) sowie die Lokation des Events (`EventLocation`). Weiterhin ist jeder Sendung ein Schiff (`VesselName`) zugeordnet. In der letzten Spalten finden Sie die Ankunftszeit in **Tagen** (`Time2Arrival`). Diese stellt die Zeit zwischen dem jeweiligen Event und dem Zielevent dar. Der Zielevent ist die Vereinnahmung der Ware (`EventName = Goods Receipt Dock`) im Werk in den USA. Der Datensatz wird um weitere abgeleitete Informationen ergänzt (`EventNameCombined`, `EventTimeMonth`, `EventTimeDay`).\n",
        "\n",
        "\n",
        "**Aufgabenstellung**\n",
        "\n",
        "Die Supply Chain Abteilung des Automobilherstellers verfolgt das Ziel, die Daten aus dem Track und Trace System für die Steuerung von Transporten und Beständen zu nutzen. Da es sich um ein neues Projekt zur intelligenten Datenanalyse handelt, wurden Sie gebeten in einem ersten Schritt die zur Verfügung gestellten Daten in Form einer explorativen Datenanalyse aufzubereiten und zu analysieren.\n",
        "\n",
        "**Konkrete Fragestellungen/ Aufgaben**\n",
        "\n",
        "\n",
        "1. Wie viele Events finden sich in dem vorliegenden Datensatz?\n",
        "1. Von welchen deutschen Häfen wird das Werk in Tuscaloosa beliefert? Filtern Sie dazu zunächst auf das Event mit dem Namen `Loading Ship`. Anschließend betrachten Sie die Werte in der Spalte `EventLocation`.\n",
        "1. Wie ist die mittlere Transportzeit (`Time2Arrival`) von jedem dieser deutschen Häfen zum Werk in den USA? Filtern Sie dazu die `EventLocation` zunächst auf die deutschen Häfen (am besten mithilfe von `isin()`) und speichern Sie die Daten in einer neuen Variablen. Anschließend müssen Sie die Daten nach Häfen gruppieren (`groupby()`) und den Mittelwert der `Time2Arrival` bilden (`mean()`).\n",
        "1. Erstellen Sie anschließend jeweils ein Histogramm zur `Time2Arrival` für jeden deutschen Hafen. Welcher Hafen hat aus Ihrer Sicht eine bessere Performance?"
      ],
      "metadata": {
        "id": "GIgxOfLYjYUs"
      },
      "id": "GIgxOfLYjYUs"
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VVNm_m9pjfws"
      },
      "id": "VVNm_m9pjfws",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 Machine Learning für Regressionprobleme <a class=\"anchor\" id=\"regression\"></a>\n",
        "Wir betrachten nun wieder den Fifa World Cup Datensatz und werden nun wie eingangs beschrieben ein ML-Verfahren verwenden, um die Anzahl der am Ende der regulären Spielzeit (ggf. plus Verlängerung) geschossenen Tore vorherzusagen. Wir nutzen zu diesem Zweck alle Informationen, die uns zur Halbzeit eines Spiels vorliegen."
      ],
      "metadata": {
        "id": "3VPZsopCh7_m"
      },
      "id": "3VPZsopCh7_m"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Datensatz in Features und Target teilen\n",
        "Zunächst einmal müssen wir unterscheiden, was vorhergesagt werden soll (**Target**) und welche Merkmale dazu genutzt werden sollen (**Features**)."
      ],
      "metadata": {
        "id": "F6l0bN2Di_at"
      },
      "id": "F6l0bN2Di_at"
    },
    {
      "cell_type": "code",
      "source": [
        "# Features, d.h. womit lässt sich die Anzahl der Tore prognostizeren!\n",
        "X = data.drop(columns=\"Total Goals\")\n",
        "X.head()"
      ],
      "metadata": {
        "id": "jw9nsecciIA0"
      },
      "id": "jw9nsecciIA0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Target, d.h. was soll prognostiziert werden!\n",
        "y = data[\"Total Goals\"]\n",
        "y.head()"
      ],
      "metadata": {
        "id": "-R0p_tMFjN-f"
      },
      "id": "-R0p_tMFjN-f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, y.shape"
      ],
      "metadata": {
        "id": "NVJdxAwwjVCf"
      },
      "id": "NVJdxAwwjVCf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Datensatz in Trainings- und Testmenge aufteilen"
      ],
      "metadata": {
        "id": "ZdIT3Aqbjc3B"
      },
      "id": "ZdIT3Aqbjc3B"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bevor wir gleich zu der Aufteilung in Trainings- & Testdaten zum Training des ML-Verfahrens kommen, müssen die nicht-numerischen Daten passend aufbereitet werden. Das Vorgehen ist dabei immer gleich. Zur Illustration nutzen wir die Fifa World Cup Daten und dabei die ersten 5 Eintragungen in der Spalte `Home Team Name`."
      ],
      "metadata": {
        "id": "ik3zan-J1vtt"
      },
      "id": "ik3zan-J1vtt"
    },
    {
      "cell_type": "code",
      "source": [
        "example = data[\"Home Team Name\"].head()\n",
        "example"
      ],
      "metadata": {
        "id": "fclb8_jk06iF"
      },
      "id": "fclb8_jk06iF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wie Ihnen bekannt, enthält die Spalte die jeweilige Heimmannschaft eines Spiels. Wenn wir mit dem Package `sklearn` und den darin verfügbaren ML-Algorithmen arbeiten, müssen wir die Datenstrutkur umwandeln. Dazu nutzen wir die Funktion `get_dummies` wie in der unteren Codezeile dargestellt."
      ],
      "metadata": {
        "id": "Hhb2asCU2TTJ"
      },
      "id": "Hhb2asCU2TTJ"
    },
    {
      "cell_type": "code",
      "source": [
        "pd.get_dummies(example)"
      ],
      "metadata": {
        "id": "fzFH4-tN1YkF"
      },
      "id": "fzFH4-tN1YkF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wir können die Funktion `get_dummies` auf den gesamten Datensatz anwenden und Pandas sucht sich selbst die umzuwandelnden Spalten.\n",
        "\n"
      ],
      "metadata": {
        "id": "FfpwR9Zd22G0"
      },
      "id": "FfpwR9Zd22G0"
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.get_dummies(X)\n",
        "X.head()"
      ],
      "metadata": {
        "id": "faK9AhsNldxt"
      },
      "id": "faK9AhsNldxt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bei der Aufteilung der Daten in Test- und Trainingsmenge hilft die Funktion `train_test_split`."
      ],
      "metadata": {
        "id": "iXcdkwur3HZI"
      },
      "id": "iXcdkwur3HZI"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "khyiUcYRjdYA"
      },
      "id": "khyiUcYRjdYA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Algorithmus: X_train (Features), y_train (Target)\n",
        "# Test des Algorithmus (Bewertung): X_test, y_test\n",
        "#     1) Algorithmus bekommt Daten (X_test), die er noch nicht kennt & macht Prognose\n",
        "#     2) Vergleich Prognose mit tatsächlichen Werte (y_test) --> Bewertung\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)"
      ],
      "metadata": {
        "id": "wRR4swbcjkRI"
      },
      "id": "wRR4swbcjkRI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Trainingsdaten:** Das jeweilige ML-Verfahren kennt `y_train` (Target, d.h. Anzahl geschossener Tore) und `X_train` (Features, d.h. die zugehörigen Merkmale des jeweiligen Spiels wie Tore zur Halbzeit etc., die das Target erklären) und versucht einen Zusammenhang zwischen diesen zu lernen!"
      ],
      "metadata": {
        "id": "P7I97YGg3cnt"
      },
      "id": "P7I97YGg3cnt"
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.head()"
      ],
      "metadata": {
        "id": "Wz3QX5_R4tiZ"
      },
      "id": "Wz3QX5_R4tiZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head()"
      ],
      "metadata": {
        "id": "YklfaWPmjm5X"
      },
      "id": "YklfaWPmjm5X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 Modell auswählen\n",
        "\n",
        "Für Regressions- und Klassifikationsprobleme gibt es eine Unmenge an ML-Verfahren. Eine Übersicht finden Sie [hier](https://scikit-learn.org/stable/). Wir werden das Verfahren `Random Forest` verwenden. Es gehört zu den besten und robustestens Verfahren im Bereich Machine Learning und wird aus diesem Grund häufig in der Praxis eingesetzt."
      ],
      "metadata": {
        "id": "qKXsT51djvLY"
      },
      "id": "qKXsT51djvLY"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor"
      ],
      "metadata": {
        "id": "x_31iuj8jvyc"
      },
      "id": "x_31iuj8jvyc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestRegressor()"
      ],
      "metadata": {
        "id": "1GKdd-yxj73L"
      },
      "id": "1GKdd-yxj73L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.4 Modell trainieren\n",
        "\n",
        "Das Random Forest Verfahren versucht nun einen Zusammenhang zwischen den Features und dem Target zu lernen und minimiert dabei ein Fehlermaß. In der Grundeinstellung wird die Summe der quadrierten Fehler minimiert, d.h. $∑(y_i - \\hat{y}_i)^2$ mit $y=$Anzahl geschossene Tore Spiel $i$ und $\\hat{y}=$Prognose Anzahl geschossene Tore Spiel $i$."
      ],
      "metadata": {
        "id": "fgPlh3stkFTt"
      },
      "id": "fgPlh3stkFTt"
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "GjXcrqj0kBqg"
      },
      "id": "GjXcrqj0kBqg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.5 Modell anwenden\n",
        "\n",
        "Zu diesem Zweck nutzen wir nun die **Testdaten**. Das ML-Verfahren erhält die Daten `X_test`, d.h. die Merkmale eines Spiels und wendet die gelernten Zusammenhänge zur Prognose des Targets an, d.h. die Anzahl der geschossenen Tore!"
      ],
      "metadata": {
        "id": "7E0hE8ZGni3Z"
      },
      "id": "7E0hE8ZGni3Z"
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.head()"
      ],
      "metadata": {
        "id": "yAtrJKMVnkT0"
      },
      "id": "yAtrJKMVnkT0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred"
      ],
      "metadata": {
        "id": "B3ORn3munk4C"
      },
      "id": "B3ORn3munk4C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.6 Modell evaluieren\n",
        "\n",
        "Nachdem nun Prognosewerte durch das angelernte Verfahren berechnet wurden, können wir diese mit den tatsächlichen Werten des Target, also der tatsächlichen Anzahl der geschossenen Tore vergleichen (`y_test`). Daraus können wir dann die Güte eines Verfahrens ableiten!"
      ],
      "metadata": {
        "id": "NpGLXSFInywW"
      },
      "id": "NpGLXSFInywW"
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics"
      ],
      "metadata": {
        "id": "oDUAdVbAnp-n"
      },
      "id": "oDUAdVbAnp-n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Genauigkeit des Modells auf der Testmenge \n",
        "sklearn.metrics.mean_absolute_error(y_test, y_pred)"
      ],
      "metadata": {
        "id": "8qwInLdwn1mF"
      },
      "id": "8qwInLdwn1mF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(y_test - y_pred).plot(\n",
        "    kind=\"hist\",\n",
        "    title= \"Histogramm Prognosefehler\",\n",
        "    figsize=(8,4),\n",
        "    color=\"c\",\n",
        "    edgecolor='k',\n",
        "    density=True,\n",
        "    alpha=0.8    \n",
        "    )\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZdlgU01hoYfI"
      },
      "id": "ZdlgU01hoYfI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Übung Machine Learning Modell mit Track & Trace Daten <a class=\"anchor\" id=\"tt_ml\"></a>\n",
        "\n",
        "Sie haben nun erfolgreich eine erste Analyse der Track & Trace Daten gemacht. Sie sollen nun versuchen, die Transportzeit von den europäischen Häfen zum Werk in den USA mithilfe von ML-Verfahren zu prognostizieren. Sollte dies gut gelingen, ist das die Grundlage um die Versorgungssicherheit zu erhöhen und Bestände im Werk zu reduzieren.\n",
        "\n",
        "Nachfolgend finden Sie die relevanten Daten mit entsprechender Filterung. Gehen Sie nun die Schritte `1-6` aus dem Kapitel \"Training eines ML-Verfahrens\" durch und wenden Sie es analog auf die Track & Trace Daten an."
      ],
      "metadata": {
        "id": "c9J_T7VPMQna"
      },
      "id": "c9J_T7VPMQna"
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df[\"EventName\"]==\"Loading Ship\"]\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Rv500VACMP2_"
      },
      "id": "Rv500VACMP2_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "irrelevant = [\"ContainerNumber\",\"ShipmentNumber\", \"EventTime\", \"EventCombined\"]\n",
        "df.drop(columns=irrelevant, inplace=True)"
      ],
      "metadata": {
        "id": "nw5WAc82BHJ9"
      },
      "id": "nw5WAc82BHJ9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "kbnOs-Sep99J"
      },
      "id": "kbnOs-Sep99J",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1) Daten in Features und Target aufteilen**"
      ],
      "metadata": {
        "id": "0GFF7htPBkLz"
      },
      "id": "0GFF7htPBkLz"
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fB6VmneNBb9c"
      },
      "id": "fB6VmneNBb9c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2) Datensatz in Trainings- und Testmenge aufteilen**"
      ],
      "metadata": {
        "id": "7zLsMVT1ByuH"
      },
      "id": "7zLsMVT1ByuH"
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6fznY_asB4Gy"
      },
      "id": "6fznY_asB4Gy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3) Modell auswählen**"
      ],
      "metadata": {
        "id": "JP9QUnxyB4zo"
      },
      "id": "JP9QUnxyB4zo"
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "535P2Qp1B8ZB"
      },
      "id": "535P2Qp1B8ZB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4) Modell trainieren**"
      ],
      "metadata": {
        "id": "rw4NuM6fB9Ae"
      },
      "id": "rw4NuM6fB9Ae"
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mKKmcutjB_R8"
      },
      "id": "mKKmcutjB_R8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5) Modell anwenden**"
      ],
      "metadata": {
        "id": "Z2Rzxy0_B_qY"
      },
      "id": "Z2Rzxy0_B_qY"
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rWQShWzzCBs2"
      },
      "id": "rWQShWzzCBs2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6) Modell evaluieren**"
      ],
      "metadata": {
        "id": "1dKRr9cfCCO8"
      },
      "id": "1dKRr9cfCCO8"
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DpG7Na7DCEdy"
      },
      "id": "DpG7Na7DCEdy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Frage:** Welche weiteren Features könnten helfen, um die Prognose der Ankunftszeit zu verbessern?"
      ],
      "metadata": {
        "id": "Iag8V-iAD_qn"
      },
      "id": "Iag8V-iAD_qn"
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JcgMaM85DUuv"
      },
      "id": "JcgMaM85DUuv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4 Machine Learning für Klassifikationsprobleme <a class=\"anchor\" id=\"klassifikation\"></a>\n",
        "Im nachfolgenden Beispiel werden wir ein ML-Verfahren einsetzen, um anhand von Untersuchungsergebnissen vorherzusagen, ob ein Patient Diabetes hat. Es handelt sich dabei um eine Klassifikationsproblem (Diabetes/ keine Diabetes). Wir verwenden einen Datensatz mit folgenden Informationen:\n",
        "1. Anzahl Schwangerschaften\n",
        "1. Glukosekonzentration nach Glukosetoleranztest\n",
        "1. Blutdruck (mm Hg)\n",
        "1. Dicke der Trizepshautfalte (mm)\n",
        "1. Insulinwert (mu U/ml)\n",
        "1. Body mass index \n",
        "1. Diabetesvorbelastungsfunktion\n",
        "1. Alter (Jahre)\n",
        "1. Diabetes (0/1)\n",
        "\n",
        "Die relevanten Daten haben die folgende Form:"
      ],
      "metadata": {
        "id": "IcxdXVt-a4Ck"
      },
      "id": "IcxdXVt-a4Ck"
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/KI_LOG_mit_PYTHON/diabetes_clean.txt\")\n",
        "data.head()"
      ],
      "metadata": {
        "id": "U_Xap0iDa8Xg"
      },
      "id": "U_Xap0iDa8Xg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 Datensatz in Features und Target teilen\n",
        "\n",
        "Wie bereits zuvor müssen wir unterscheiden, was vorhergesagt werden soll (**Target**) und welche Merkmale dazu genutzt werden sollen (**Features**)."
      ],
      "metadata": {
        "id": "HsigSaVPCMeT"
      },
      "id": "HsigSaVPCMeT"
    },
    {
      "cell_type": "code",
      "source": [
        "# Features, d.h. womit lässt sich Diabetes prognostizeren!\n",
        "X = data.drop(columns=\"diabetes\")\n",
        "X.head()"
      ],
      "metadata": {
        "id": "z-uyIdD-d-eB"
      },
      "id": "z-uyIdD-d-eB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Target, d.h. was soll prognostiziert werden!\n",
        "y = data[\"diabetes\"]\n",
        "y.head()"
      ],
      "metadata": {
        "id": "vmpeKoYICZUE"
      },
      "id": "vmpeKoYICZUE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 Datensatz in Trainings- und Testmenge aufteilen\n",
        "Erneut müssen wir die Daten aufteilen. Da wir ausschließlich mit numerischen Daten arbeiten, müssen wir keine Datenaufbereitung über `pd.get_dummies` vornehmen."
      ],
      "metadata": {
        "id": "l2eJRG5ICjbo"
      },
      "id": "l2eJRG5ICjbo"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "DkUWgtB8DKCI"
      },
      "id": "DkUWgtB8DKCI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X und y werden in Trainings- und Testmenge aufgeteilt, so dass die Testmenge 20% der vorhandenen Daten hat\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)"
      ],
      "metadata": {
        "id": "QVKROgWUCeP_"
      },
      "id": "QVKROgWUCeP_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.head()"
      ],
      "metadata": {
        "id": "ajWtX075CxNn"
      },
      "id": "ajWtX075CxNn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head()"
      ],
      "metadata": {
        "id": "SApJDY4jDZJW"
      },
      "id": "SApJDY4jDZJW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3 Modell auswählen\n",
        "\n",
        "Erneut verwenden wir das Verfahren `Random Forest`. Sie müssen allerdings darauf achten, dass Sie einen Random Forest zur Klassifikation importieren. Aus diesem Grund verwenden wir das Verfahren `RandomForestClassifier`. Für die Regressionaufgabe hatten wir das Verfahren `RandomForestRegressor` genutzt. Achten Sie auf diesen wichtigen Unterschied!"
      ],
      "metadata": {
        "id": "DZH4B74CDepm"
      },
      "id": "DZH4B74CDepm"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "hRJ3fQsFDXL_"
      },
      "id": "hRJ3fQsFDXL_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestClassifier()"
      ],
      "metadata": {
        "id": "cKGnyxJRDqIY"
      },
      "id": "cKGnyxJRDqIY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.4 Modell trainieren\n",
        "\n",
        "Das Random Forest Verfahren versucht nun einen Zusammenhang zwischen den Features und dem Target zu lernen und minimiert dabei ein Fehlermaß. Letzteres misst den Grad der Fehlklassifikation. Beispiel für Fehlklassifikation: Das Modell prognostiziert Diabetes für einen Patienten, in der Realität liegt die Erkrankung aber nicht vor."
      ],
      "metadata": {
        "id": "LatzmZt2Dxj6"
      },
      "id": "LatzmZt2Dxj6"
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "ioXqSKqaDslO"
      },
      "id": "ioXqSKqaDslO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.5 Modell anwenden\n",
        "\n",
        "Das ML-Verfahren erhält die Daten `X_test`, d.h. die Untersuchungsergebnisse mit den relevanten Merkmalen und wendet die gelernten Zusammenhänge zur Prognose des Targets an, d.h. dem Vorhandensein von Diabetes (0/1)!"
      ],
      "metadata": {
        "id": "SnHwdqNWESSV"
      },
      "id": "SnHwdqNWESSV"
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.head(2)"
      ],
      "metadata": {
        "id": "ugENEj5fWHjx"
      },
      "id": "ugENEj5fWHjx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "Lw2VrYolEL1G"
      },
      "id": "Lw2VrYolEL1G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.6 Modell evaluieren\n",
        "\n",
        "Die Modellbewertung erfolgt bei der Klassifikation regelmäßg nach dem Kriterium der \"Accuracy\" (andere kommen aber auch zum Einsatz). Die Accuracy setzt die Anzahl der korrekten Klassifikation in das Verhältnis zur Anzahl aller Beobachtungen. Dementsprechend stellt sie den Anteil der korrekten Klassifikationen dar."
      ],
      "metadata": {
        "id": "2LtmLpD4EkIp"
      },
      "id": "2LtmLpD4EkIp"
    },
    {
      "cell_type": "code",
      "source": [
        "sklearn.metrics.accuracy_score(y_test, y_pred) * 100"
      ],
      "metadata": {
        "id": "QFRaMmh7Ef47"
      },
      "id": "QFRaMmh7Ef47",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zur Veranschaulichung von Klassifikationsergebnissen hilft regelmäßig eine Konfusionsmatrix. Diese wird wie folgt erstellt:"
      ],
      "metadata": {
        "id": "G_zYj8rkOeuS"
      },
      "id": "G_zYj8rkOeuS"
    },
    {
      "cell_type": "code",
      "source": [
        "conf_matrix = sklearn.metrics.confusion_matrix(y_test, y_pred, labels=model.classes_)\n",
        "disp = sklearn.metrics.ConfusionMatrixDisplay(conf_matrix, display_labels=model.classes_)\n",
        "disp.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "g_2GU6ppEvOP"
      },
      "id": "g_2GU6ppEvOP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.7 Beispiel Vorhersage der Anzahl von Schwangerschaften"
      ],
      "metadata": {
        "id": "E02vjECMHydd"
      },
      "id": "E02vjECMHydd"
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelltraining\n",
        "# 1. Datenaufteilung in X und y\n",
        "X = data.drop(columns=\"schwangerschaften\")\n",
        "y = data[\"schwangerschaften\"]\n",
        "# 2. Datenaufteilung in X_train, X_test, y_train, y_test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)\n",
        "# 3. Modell trainieren\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "uUOCSeTVH6Nd"
      },
      "id": "uUOCSeTVH6Nd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modellanwendung Person1\n",
        "person = data.head(1).drop(columns=\"schwangerschaften\").copy()\n",
        "person"
      ],
      "metadata": {
        "id": "wT2uNxBZIQ8N"
      },
      "id": "wT2uNxBZIQ8N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(person)"
      ],
      "metadata": {
        "id": "u86KU1_kJHyZ"
      },
      "id": "u86KU1_kJHyZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modellanwendung Person2\n",
        "person[\"bmi\"]=20\n",
        "person[\"diabetes\"]=0\n",
        "person[\"alter\"]=25"
      ],
      "metadata": {
        "id": "7d1FuHqbKEuH"
      },
      "id": "7d1FuHqbKEuH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(person)"
      ],
      "metadata": {
        "id": "GnBelnzIKEM2"
      },
      "id": "GnBelnzIKEM2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Abschlussübung Machine Learning <a class=\"anchor\" id=\"final\"></a>\n",
        "Wir bleiben beim Datensatz zur Diabetes. Entwickeln Sie ein Machine Learning Modell, welches den BMI einer untersuchten Person auf Basis der Untersuchungsergebnisse (inkl. Diabetesbefund) vorhersagt!"
      ],
      "metadata": {
        "id": "lqGYeZEjOrwp"
      },
      "id": "lqGYeZEjOrwp"
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "83cyBO79F0q1"
      },
      "id": "83cyBO79F0q1",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "G1 Machine Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}